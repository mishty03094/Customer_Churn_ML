# -*- coding: utf-8 -*-
"""Copy of CustomerChurn

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q8SPdH_VfGeAL9iob7y7AfDTu2wi01YF

**Importing necessary libraries to clean and analyse the data**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

raw_df=pd.read_csv('/content/WA_Fn-UseC_-Telco-Customer-Churn.csv')

raw_df.head(25)

raw_df.info()

raw_df.shape

for col in raw_df.columns:
  print(col,raw_df[col].isnull().sum())

raw_df[raw_df['Churn']=='No']

"""**Data Cleaning**"""

df1=raw_df.copy()

df1.drop('customerID',axis=1,inplace=True)

df1

"""**Categorical to Numeric Conversion**"""

gender_mapping = {'Male': 0, 'Female': 1}


df1['gender'] = df1['gender'].map(gender_mapping)

df1.head()



#true false mapping to 0 and 1
mapping = {'Yes': 1, 'No': 0}

df1['Partner'] = df1['Partner'].map(mapping)
df1['Dependents'] = df1['Dependents'].map(mapping)
df1['PhoneService'] = df1['PhoneService'].map(mapping)
df1['PaperlessBilling'] = df1['PaperlessBilling'].map(mapping)
df1['Churn'] = df1['Churn'].map(mapping)

df1['OnlineSecurity'] = df1['OnlineSecurity'].map(mapping)
df1['OnlineBackup'] = df1['OnlineBackup'].map(mapping)
df1['DeviceProtection'] = df1['DeviceProtection'].map(mapping)
df1['TechSupport'] = df1['TechSupport'].map(mapping)
df1['StreamingTV'] = df1['StreamingTV'].map(mapping)
df1['StreamingMovies'] = df1['StreamingMovies'].map(mapping)

df1.head()



df1

df1.info()

df2=df1.copy()

df2.shape

df2

#one hot encoding
encoded_df = pd.get_dummies(df2, columns=['MultipleLines', 'InternetService', 'Contract', 'PaymentMethod'])

encoded_df.head()

encoded_df[encoded_df['InternetService_No']==True]

encoded_df.head()

encoded_df.info()

for col in encoded_df.columns:
  print(col)

mapping={True:1,False:0}
encoded_df['Contract_Month-to-month']=encoded_df['Contract_Month-to-month'].map(mapping)
encoded_df['Contract_One year']=encoded_df['Contract_One year'].map(mapping)
encoded_df['Contract_Two year']=encoded_df['Contract_Two year'].map(mapping)

encoded_df.head()

encoded_df['PaymentMethod_Bank transfer (automatic)']=encoded_df['PaymentMethod_Bank transfer (automatic)'].map(mapping)
encoded_df['PaymentMethod_Credit card (automatic)']=encoded_df['PaymentMethod_Credit card (automatic)'].map(mapping)
encoded_df['PaymentMethod_Electronic check']=encoded_df['PaymentMethod_Electronic check'].map(mapping)
encoded_df['PaymentMethod_Mailed check']=encoded_df['PaymentMethod_Mailed check'].map(mapping)

encoded_df.head()

encoded_df['InternetService_DSL']=encoded_df['InternetService_DSL'].map(mapping)
encoded_df['InternetService_Fiber optic']=encoded_df['InternetService_Fiber optic'].map(mapping)
encoded_df['InternetService_No']=encoded_df['InternetService_No'].map(mapping)

encoded_df['MultipleLines_No']=encoded_df['MultipleLines_No'].map(mapping)
encoded_df['MultipleLines_No phone service']=encoded_df['MultipleLines_No phone service'].map(mapping)
encoded_df['MultipleLines_Yes']=encoded_df['MultipleLines_Yes'].map(mapping)

encoded_df.info()

encoded_df.TotalCharges = pd.to_numeric(encoded_df.TotalCharges, errors='coerce')

encoded_df.info()

encoded_df.shape

df2.shape

for col in df2.columns:
  print(col,df2[col].isnull().sum())

for col in encoded_df.columns:
  print(col,encoded_df[col].isnull().sum())



"""**Data Visualisation using Matplotlib and Seaborn**

Use df2 and encoded_df for this:

**df2**= has null values deleted, categorical **data with two categories (yes, no) or (true, false) converted to numeric data i.e 0,1 values** where **0 is False/no** and **1 is true/yes**, except for gender where **0=female and 1= male**.

**encoded_df**= has null values deleted, everything that df2 has and data with more than two categories has been converted to numerical data using one hot encoding technique.

"""

import matplotlib.pyplot as plt
import seaborn as sns

#visualize the distribution of targrt variable 'churn'

sns.countplot(x='Churn',data= df2)
plt.title('Churn distribution in df2')
plt.show()



"""According to this graph , most of the people do not churn very less coustomers churn so we have unbalanced data

"""



#visualising the distribution of tenure
sns.histplot(data=df2, x='tenure', hue='Churn', multiple='stack', bins=20)
plt.title('Tenure Distribution by Churn in df2')
plt.xlabel('Tenure in months')
plt.ylabel('Number of Customers')
plt.show()

"""According to this whose tenure is less they churn more

"""

# Visualising the distribution of Monthly charges
sns.histplot(data=df2, x='MonthlyCharges', hue='Churn', multiple='stack', bins=20)
plt.title('Monthly Charges Distribution by Churn in df2')
plt.xlabel('Monthly Charges in $')
plt.ylabel('Number of Customers')
plt.show()

"""According to this, wgen range is between 20-70 the customer does not churn but when the monthly charges increase the ratio of churn also increased

"""

# Visualising the distribution of gender
sns.countplot(x='gender', hue='Churn', data=df2)
plt.title('Gender Distribution by Churn in df2')
plt.show()



"""According to this, churn does not dependent on gender

"""

'''
#Visualising the distribution of Internet Service
sns.countplot(x='InternetService', hue='Churn', data=df2)
plt.title('Internet Service Distribution by Churn in df2')
plt.show()
'''

# Correlation
plt.figure(figsize=(15,8))
encoded_df.corr()['Churn'].sort_values(ascending = False).plot(kind='bar')

"""According to this , the correlation is of same type for partners , dependents , device protection , online backup and total charges

According to this , on techsupport and onlinesecurity correlation is negative

According to this when a Payment Method is of electric check the churn is positive but in all other scnerio churn is negative

According to this the churn is positive in senior citizen and paperlessbiling

According to this when a customer take internet service of fibre optic type the churn is positive but when a customer take internet service of DSL type the churn is less negative comparitively than internet service not taken

According to this when contract is of month to month the churn is positive but when the contract is of one and two year the churn is negative

According to this, multipleLines , PhoneService , gender , Streaming dose not significantly depend on churn
"""

ax = df2['Contract'].value_counts().plot(kind = 'bar',rot = 0, width = 0.2)
ax.set_ylabel('No of Customers')
ax.set_title('No of Customers by Contract Type')

"""According to this, churn is depend on month-to-month contract mainly other than both have same dependent"""

services = ['PhoneService','MultipleLines','InternetService','OnlineSecurity',
           'OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']

fig, axes = plt.subplots(nrows = 3,ncols = 3,figsize = (15,12))
for i, item in enumerate(services):
    if i < 3:
        ax = df2[item].value_counts().plot(kind = 'bar',ax=axes[i,0],rot = 0)

    elif i >=3 and i < 6:
        ax = df2[item].value_counts().plot(kind = 'bar',ax=axes[i-3,1],rot = 0)

    elif i < 9:
        ax = df2[item].value_counts().plot(kind = 'bar',ax=axes[i-6,2],rot = 0)
    ax.set_title(item)
    plt.subplots_adjust(hspace=0.5, wspace=0.3)

services = ['PhoneService','MultipleLines','InternetService','OnlineSecurity',
           'OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']

fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 12))
def plot_service_churn(service, ax):
    counts = df2.groupby([service, 'Churn']).size().unstack(fill_value=0)
    counts.plot(kind='bar', stacked=True, ax=ax, color=['blue', 'red'], rot=0)
    ax.set_title(service)

for i, service in enumerate(services):
    if i < 3:
        ax = axes[i, 0]
    elif i >= 3 and i < 6:
        ax = axes[i - 3, 1]
    else:
        ax = axes[i - 6, 2]
    plot_service_churn(service, ax)

plt.subplots_adjust(hspace=0.5, wspace=0.3)
plt.show()

sns.countplot(x='SeniorCitizen',data= df2)
plt.title('Senior citizen distribution in df2')
plt.show()

"""Majorly, we dont have senior citizens"""

# Visualising the distribution of Monthly charges
sns.histplot(data=df2, x='PaperlessBilling', hue='Churn', multiple='stack')
plt.title('Paperless Billing Distribution by Churn in df2')
plt.xlabel('Paperless Billin')
plt.ylabel('Number of Customers')
plt.show()

# Visualising the distribution of gender
sns.countplot(x='SeniorCitizen', hue='Churn', data=df2)
plt.title('Senior citizen Distribution by Churn in df2')
plt.show()

"""If someone is a senior citizen, they are equally likel;y to churn or no churn, but if they are not a senior citizen then they are more likely to not churn"""

# Visualising the distribution of Monthly charges
sns.histplot(data=df2, x='OnlineBackup', hue='Churn', multiple='stack')
plt.title('ONline Backup Distribution by Churn in df2')
plt.xlabel('ONline Backup')
plt.ylabel('Number of Customers')
plt.show()

"""if there is online backup, customer is less likely to churn"""

# Visualising the distribution of Monthly charges
sns.histplot(data=df2, x='OnlineSecurity', hue='Churn', multiple='stack')
plt.title('Online Sec Distribution by Churn in df2')
plt.xlabel('Online Sec')
plt.ylabel('Number of Customers')
plt.show()

# Visualising the distribution of Monthly charges
sns.histplot(data=encoded_df, x='Contract_One year', hue='Churn', multiple='stack')
plt.title('1 year contract by churn')
plt.xlabel('1 year contract')
plt.ylabel('Number of Customers')
plt.show()

# Visualising the distribution of Monthly charges
sns.histplot(data=encoded_df, x='Contract_Two year', hue='Churn', multiple='stack')
plt.title('2 year contract Distribution by Churn in df2')
plt.xlabel('2 year contract')
plt.ylabel('Number of Customers')
plt.show()

# Visualising the distribution of Monthly charges
sns.histplot(data=encoded_df, x='InternetService_No', hue='Churn', multiple='stack')
plt.title('Paperless Billing Distribution by Churn in df2')
plt.xlabel('Paperless Billin')
plt.ylabel('Number of Customers')
plt.show()

"""if there is online security, then churn is more likely to be 0

Till now we have figured out:
**Contract**: if it is monthly, then customer is more likely to churn, but if it two year long then customer is most likey to stay, whereas if its annual then again, the customer is more likely to stay

**Internet Service**: if it is fiber optic then the customer is more likely to churn else for no internet service the customer might not churn and for DSL too, the customer might not churn.

**Tenure**: for high tenure, churn chances are low. That means the loyal customer base stays.

**Payment Method**: for electronic check the customer is more likely to churn.

**Online Security**: If true, churn is more liekly to be false

**Tech Suppport**: If true,churn is more likely to be false

**Monthly Charges**: More the monthly charges, more are the chances that customre will churn

**total charges, online backup, device protection, partner, depedent**: if true churn is more likely to be false

**Paperless Billing**: More likely to churn if true

**Senior citizen**: More likely to churn
"""

df2.info()

df2.describe()

encoded_df.describe()

encoded_df.info()

"""**Balancing the dataset and spiltting **
Balancing: using random oversampler
Split: 80% train 20% test
"""

final=encoded_df.copy()

null_cols = [col for col in final.columns if final[col].isnull().all()]
print(null_cols)

final.dropna(thresh=1, inplace=True)

final.head(50)

final.dropna(how='all')

final.head(50)

final.fillna(0)

final.head(50)

columns_to_fill = ['OnlineSecurity' ,
    'OnlineBackup',
    'DeviceProtection' ,
    'TechSupport',
   'StreamingTV',
   'StreamingMovies'  ]
mask = final['InternetService_No'] == 1
for col in columns_to_fill:
    final.loc[mask, col] = 0

final[final["InternetService_No"]==True]

from imblearn.over_sampling import RandomOverSampler
from sklearn.model_selection import train_test_split

X = final.drop('Churn', axis=1) #features
y = final['Churn'] #target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

ros = RandomOverSampler(random_state=42)

X_train_res, y_train_res = ros.fit_resample(X_train, y_train)

X_test['TotalCharges'].fillna(X_train_res['TotalCharges'].mean(), inplace=True)

print("Null values in x_train_res:")
print(X_train_res.isnull().sum())

print("\nNull values in y_train_res:")
print(y_train_res.isnull().sum())

X_train_res['TotalCharges'].fillna(X_train_res['TotalCharges'].mean(), inplace=True)

"""**Linear Regression Model**"""

from sklearn.linear_model import LinearRegression

from sklearn.metrics import mean_squared_error, r2_score

import matplotlib.pyplot as plt
import numpy as np

lr_model = LinearRegression()

# Train the model on the resampled data
lr_model.fit(X_train_res, y_train_res)

# Make predictions on the testing data
y_pred = lr_model.predict(X_test)

# Evaluate the model using Mean Squared Error (MSE) and R-squared
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Plot actual vs predicted values
plt.figure(figsize=(14, 6))

# Scatter plot of actual vs predicted values
plt.subplot(1, 2, 1)
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Actual vs Predicted Values')

# Plot residuals
plt.subplot(1, 2, 2)
sns.histplot(y_test - y_pred, kde=True, bins=30)
plt.xlabel('Residuals')
plt.title('Residuals Distribution')

plt.tight_layout()
plt.show()

print(mse)
print(r2)

print(y_test)

print(y_pred)

print(X_test)

"""**Logistic Regression Model**"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,roc_curve, roc_auc_score

# Assume X_train_res and y_train_res are your training data

# Split data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X_train_res, y_train_res, test_size=0.2, random_state=42)

# Create a Logistic Regression model
log_reg = LogisticRegression(max_iter=1000)

# Train the model on the training data
log_reg.fit(X_train, y_train)

# Make predictions on the validation set
y_pred = log_reg.predict(X_val)
y_pred_proba = log_reg.predict_proba(X_val)[:, 1]

# Evaluate the model
accuracy = accuracy_score(y_val, y_pred)
print("Accuracy:", accuracy)

# Print classification report
print("Classification Report:")
print(classification_report(y_val, y_pred))

# Print confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_val, y_pred))

# ROC-AUC curve
fpr, tpr, _ = roc_curve(y_val, y_pred_proba)
roc_auc = roc_auc_score(y_val, y_pred_proba)

plt.figure(figsize=(15, 5))

# Plot ROC-AUC curve
plt.subplot(1, 3, 1)
plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC-AUC Curve')
plt.legend(loc='lower right')

# Sigmoid function plot
plt.subplot(1, 3, 3)
x = np.linspace(-10, 10, 400)
y = 1 / (1 + np.exp(-x))
plt.plot(x, y, color='green')
plt.title('Sigmoid Function')
plt.xlabel('x')
plt.ylabel('Sigmoid(x)')

plt.tight_layout()
plt.show()

"""**KNN**"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, roc_auc_score


# Split data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X_train_res, y_train_res, test_size=0.2, random_state=42)

# Create a KNN model with k=5
knn = KNeighborsClassifier(n_neighbors=5)

# Train the model on the training data
knn.fit(X_train, y_train)

# Make predictions on the validation set
y_pred = knn.predict(X_val)
y_pred_prob = knn.predict_proba(X_val)[:, 1]

# Evaluate the model
accuracy = accuracy_score(y_val, y_pred)
print("Accuracy:", accuracy)

# Print classification report
print("Classification Report:")
print(classification_report(y_val, y_pred))

# Print confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_val, y_pred))

# Calculate AUC
auc = roc_auc_score(y_val, y_pred_prob)

# ROC curve plot with AUC
plt.subplot(1, 2, 2)
fpr, tpr, _ = roc_curve(y_val, y_pred_prob)
plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % auc)
plt.plot([0, 1], [0, 1], color='red', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")

plt.tight_layout()
plt.show()

# Create a KNN model with k=5
knn = KNeighborsClassifier(n_neighbors=3)

# Train the model on the training data
knn.fit(X_train, y_train)

# Make predictions on the validation set
y_pred = knn.predict(X_val)

# Evaluate the model
accuracy = accuracy_score(y_val, y_pred)
print("Accuracy:", accuracy)

# Print classification report
print("Classification Report:")
print(classification_report(y_val, y_pred))

# Print confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_val, y_pred))

from sklearn.neighbors import KNeighborsClassifier



# Split data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X_train_res, y_train_res, test_size=0.2, random_state=42)

# Create a KNN model with k=5
knn = KNeighborsClassifier(n_neighbors=7)

# Train the model on the training data
knn.fit(X_train, y_train)

# Make predictions on the validation set
y_pred = knn.predict(X_val)

# Evaluate the model
accuracy = accuracy_score(y_val, y_pred)
print("Accuracy:", accuracy)

# Print classification report
print("Classification Report:")
print(classification_report(y_val, y_pred))

# Print confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_val, y_pred))

# Create a KNN model with k=5
knn = KNeighborsClassifier(n_neighbors=9)

# Train the model on the training data
knn.fit(X_train, y_train)

# Make predictions on the validation set
y_pred = knn.predict(X_val)

# Evaluate the model
accuracy = accuracy_score(y_val, y_pred)
print("Accuracy:", accuracy)

# Print classification report
print("Classification Report:")
print(classification_report(y_val, y_pred))

# Print confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_val, y_pred))

# Create a KNN model with k=5
knn = KNeighborsClassifier(n_neighbors=3,metric='manhattan')

# Train the model on the training data
knn.fit(X_train, y_train)

# Make predictions on the validation set
y_pred = knn.predict(X_val)

# Evaluate the model
accuracy = accuracy_score(y_val, y_pred)
print("Accuracy:", accuracy)

# Print classification report
print("Classification Report:")
print(classification_report(y_val, y_pred))

# Print confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_val, y_pred))

# Create a KNN model with k=5
knn = KNeighborsClassifier(n_neighbors=5,metric='manhattan')

# Train the model on the training data
knn.fit(X_train, y_train)

# Make predictions on the validation set
y_pred = knn.predict(X_val)

# Evaluate the model
accuracy = accuracy_score(y_val, y_pred)
print("Accuracy:", accuracy)

# Print classification report
print("Classification Report:")
print(classification_report(y_val, y_pred))

# Print confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_val, y_pred))

# Create a KNN model with k=5
knn = KNeighborsClassifier(n_neighbors=7,metric='manhattan')

# Train the model on the training data
knn.fit(X_train, y_train)

# Make predictions on the validation set
y_pred = knn.predict(X_val)

# Evaluate the model
accuracy = accuracy_score(y_val, y_pred)
print("Accuracy:", accuracy)

# Print classification report
print("Classification Report:")
print(classification_report(y_val, y_pred))

# Print confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_val, y_pred))

# Create a KNN model with k=5
knn = KNeighborsClassifier(n_neighbors=9,metric='manhattan')

# Train the model on the training data
knn.fit(X_train, y_train)

# Make predictions on the validation set
y_pred = knn.predict(X_val)

# Evaluate the model
accuracy = accuracy_score(y_val, y_pred)
print("Accuracy:", accuracy)

# Print classification report
print("Classification Report:")
print(classification_report(y_val, y_pred))

# Print confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_val, y_pred))

# Create a KNN model with k=5
knn = KNeighborsClassifier(n_neighbors=3,metric='minkowski', p=3)

# Train the model on the training data
knn.fit(X_train, y_train)

# Make predictions on the validation set
y_pred = knn.predict(X_val)

# Evaluate the model
accuracy = accuracy_score(y_val, y_pred)
print("Accuracy:", accuracy)

# Print classification report
print("Classification Report:")
print(classification_report(y_val, y_pred))

# Print confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_val, y_pred))

# Create a KNN model with k=5
knn = KNeighborsClassifier(n_neighbors=5,metric='minkowski', p=3)

# Train the model on the training data
knn.fit(X_train, y_train)

# Make predictions on the validation set
y_pred = knn.predict(X_val)

# Evaluate the model
accuracy = accuracy_score(y_val, y_pred)
print("Accuracy:", accuracy)

# Print classification report
print("Classification Report:")
print(classification_report(y_val, y_pred))

# Print confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_val, y_pred))

# Create a KNN model with k=5
knn = KNeighborsClassifier(n_neighbors=7,metric='minkowski', p=3)

# Train the model on the training data
knn.fit(X_train, y_train)

# Make predictions on the validation set
y_pred = knn.predict(X_val)

# Evaluate the model
accuracy = accuracy_score(y_val, y_pred)
print("Accuracy:", accuracy)

# Print classification report
print("Classification Report:")
print(classification_report(y_val, y_pred))

# Print confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_val, y_pred))

# Create a KNN model with k=5
knn = KNeighborsClassifier(n_neighbors=3,metric='minkowski', p=5)

# Train the model on the training data
knn.fit(X_train, y_train)

# Make predictions on the validation set
y_pred = knn.predict(X_val)

# Evaluate the model
accuracy = accuracy_score(y_val, y_pred)
print("Accuracy:", accuracy)

# Print classification report
print("Classification Report:")
print(classification_report(y_val, y_pred))

# Print confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_val, y_pred))

# Create a KNN model with k=5
knn = KNeighborsClassifier(n_neighbors=5,metric='minkowski', p=5)

# Train the model on the training data
knn.fit(X_train, y_train)

# Make predictions on the validation set
y_pred = knn.predict(X_val)

# Evaluate the model
accuracy = accuracy_score(y_val, y_pred)
print("Accuracy:", accuracy)

# Print classification report
print("Classification Report:")
print(classification_report(y_val, y_pred))

# Print confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_val, y_pred))

# Create a KNN model with k=5
knn = KNeighborsClassifier(n_neighbors=7,metric='minkowski', p=5)

# Train the model on the training data
knn.fit(X_train, y_train)

# Make predictions on the validation set
y_pred = knn.predict(X_val)

# Evaluate the model
accuracy = accuracy_score(y_val, y_pred)
print("Accuracy:", accuracy)

# Print classification report
print("Classification Report:")
print(classification_report(y_val, y_pred))

# Print confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_val, y_pred))

knn_chebyshev = KNeighborsClassifier(n_neighbors=3, metric='chebyshev')

# Train the model on the training data
knn_chebyshev.fit(X_train, y_train)

# Make predictions on the validation set
y_pred_chebyshev = knn_chebyshev.predict(X_val)

# Evaluate the model
accuracy_chebyshev = accuracy_score(y_val, y_pred_chebyshev)
print("Accuracy with Chebyshev distance:", accuracy_chebyshev)

# Print classification report
print("Classification Report with Chebyshev distance:")
print(classification_report(y_val, y_pred_chebyshev))

# Print confusion matrix
print("Confusion Matrix with Chebyshev distance:")
print(confusion_matrix(y_val, y_pred_chebyshev))

knn_chebyshev = KNeighborsClassifier(n_neighbors=5, metric='chebyshev')

# Train the model on the training data
knn_chebyshev.fit(X_train, y_train)

# Make predictions on the validation set
y_pred_chebyshev = knn_chebyshev.predict(X_val)

# Evaluate the model
accuracy_chebyshev = accuracy_score(y_val, y_pred_chebyshev)
print("Accuracy with Chebyshev distance:", accuracy_chebyshev)

# Print classification report
print("Classification Report with Chebyshev distance:")
print(classification_report(y_val, y_pred_chebyshev))

# Print confusion matrix
print("Confusion Matrix with Chebyshev distance:")
print(confusion_matrix(y_val, y_pred_chebyshev))

knn_chebyshev = KNeighborsClassifier(n_neighbors=7, metric='chebyshev')

# Train the model on the training data
knn_chebyshev.fit(X_train, y_train)

# Make predictions on the validation set
y_pred_chebyshev = knn_chebyshev.predict(X_val)

# Evaluate the model
accuracy_chebyshev = accuracy_score(y_val, y_pred_chebyshev)
print("Accuracy with Chebyshev distance:", accuracy_chebyshev)

# Print classification report
print("Classification Report with Chebyshev distance:")
print(classification_report(y_val, y_pred_chebyshev))

# Print confusion matrix
print("Confusion Matrix with Chebyshev distance:")
print(confusion_matrix(y_val, y_pred_chebyshev))

knn_hamming = KNeighborsClassifier(n_neighbors=3, metric='hamming')

# Train the model on the training data
knn_hamming.fit(X_train, y_train)

# Make predictions on the validation set
y_pred_hamming = knn_hamming.predict(X_val)

# Evaluate the model
accuracy_hamming = accuracy_score(y_val, y_pred_hamming)
print("Accuracy with Hamming distance:", accuracy_hamming)

# Print classification report
print("Classification Report with Hamming distance:")
print(classification_report(y_val, y_pred_hamming))

# Print confusion matrix
print("Confusion Matrix with Hamming distance:")
print(confusion_matrix(y_val, y_pred_hamming))

knn_hamming = KNeighborsClassifier(n_neighbors=5, metric='hamming')

# Train the model on the training data
knn_hamming.fit(X_train, y_train)

# Make predictions on the validation set
y_pred_hamming = knn_hamming.predict(X_val)

# Evaluate the model
accuracy_hamming = accuracy_score(y_val, y_pred_hamming)
print("Accuracy with Hamming distance:", accuracy_hamming)

# Print classification report
print("Classification Report with Hamming distance:")
print(classification_report(y_val, y_pred_hamming))

# Print confusion matrix
print("Confusion Matrix with Hamming distance:")
print(confusion_matrix(y_val, y_pred_hamming))

knn_hamming = KNeighborsClassifier(n_neighbors=7, metric='hamming')

# Train the model on the training data
knn_hamming.fit(X_train, y_train)

# Make predictions on the validation set
y_pred_hamming = knn_hamming.predict(X_val)

# Evaluate the model
accuracy_hamming = accuracy_score(y_val, y_pred_hamming)
print("Accuracy with Hamming distance:", accuracy_hamming)

# Print classification report
print("Classification Report with Hamming distance:")
print(classification_report(y_val, y_pred_hamming))

# Print confusion matrix
print("Confusion Matrix with Hamming distance:")
print(confusion_matrix(y_val, y_pred_hamming))

"""**Decision Tree**"""

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
from sklearn import tree
from imblearn.over_sampling import RandomOverSampler
import numpy as np
import pandas as pd

# Assuming X and y are defined
# X should be a pandas DataFrame so we can get the column names
# y should be the target variable

# Define feature names
feature_names = X.columns.tolist()  # if X is a DataFrame

# Define class names
class_names = ['No Churn', 'Churn']  # or however your classes are named

# Check the distribution of the target variable in the original dataset
print("Distribution in the original dataset:")
print(y.value_counts())

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Apply RandomOverSampler to balance the classes in the training set
ros = RandomOverSampler(random_state=42)
X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)

# Check the distribution of the target variable in the resampled training set
print("\nDistribution in the resampled training set:")
print(pd.Series(y_train_resampled).value_counts())

# Create a Decision Tree model with Gini impurity (default)
dt_gini = DecisionTreeClassifier(random_state=42)
dt_gini.fit(X_train_resampled, y_train_resampled)

# Create a Decision Tree model with Entropy
dt_entropy = DecisionTreeClassifier(random_state=42, criterion='entropy')
dt_entropy.fit(X_train_resampled, y_train_resampled)

# Make predictions on the testing set for both models
y_pred_gini = dt_gini.predict(X_test)
y_pred_entropy = dt_entropy.predict(X_test)

# Evaluate the models
accuracy_gini = accuracy_score(y_test, y_pred_gini)
accuracy_entropy = accuracy_score(y_test, y_pred_entropy)

print("Accuracy with Gini:", accuracy_gini)
print("Accuracy with Entropy:", accuracy_entropy)

print("\nClassification Report with Gini:")
print(classification_report(y_test, y_pred_gini))

print("\nClassification Report with Entropy:")
print(classification_report(y_test, y_pred_entropy))

print("\nConfusion Matrix with Gini:")
print(confusion_matrix(y_test, y_pred_gini))

print("\nConfusion Matrix with Entropy:")
print(confusion_matrix(y_test, y_pred_entropy))

# Plot the decision trees
plt.figure(figsize=(20,10))
plt.title("Decision Tree with Gini Impurity")
tree.plot_tree(dt_gini, filled=True, feature_names=feature_names, class_names=class_names)
plt.show()

plt.figure(figsize=(20,10))
plt.title("Decision Tree with Entropy")
tree.plot_tree(dt_entropy, filled=True, feature_names=feature_names, class_names=class_names)
plt.show()

# Access and print impurity values
n_nodes_gini = dt_gini.tree_.node_count
impurity_gini = dt_gini.tree_.impurity

n_nodes_entropy = dt_entropy.tree_.node_count
impurity_entropy = dt_entropy.tree_.impurity

print("\nImpurity values with Gini:")
for node in range(n_nodes_gini):
    print(f"Node {node}: Impurity = {impurity_gini[node]:.4f}")

print("\nImpurity values with Entropy:")
for node in range(n_nodes_entropy):
    print(f"Node {node}: Impurity = {impurity_entropy[node]:.4f}")

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
from sklearn import tree
import numpy as np

# Assuming X and y are defined
# X should be a pandas DataFrame so we can get the column names
# y should be the target variable

# Define feature names
feature_names = X.columns.tolist()  # if X is a DataFrame

# Define class names
class_names = ['No Churn', 'Churn']  # or however your classes are named



# Create a Decision Tree model with Gini impurity (default)
dt_gini = DecisionTreeClassifier(random_state=42)
dt_gini.fit(X_train_res, y_train_res)

# Create a Decision Tree model with Entropy
dt_entropy = DecisionTreeClassifier(random_state=42, criterion='entropy')
dt_entropy.fit(X_train_res, y_train_res)

# Make predictions on the testing set for both models
y_pred_gini = dt_gini.predict(X_test)
y_pred_entropy = dt_entropy.predict(X_test)

# Evaluate the models
accuracy_gini = accuracy_score(y_test, y_pred_gini)
accuracy_entropy = accuracy_score(y_test, y_pred_entropy)

print("Accuracy with Gini:", accuracy_gini)
print("Accuracy with Entropy:", accuracy_entropy)

print("\nClassification Report with Gini:")
print(classification_report(y_test, y_pred_gini))

print("\nClassification Report with Entropy:")
print(classification_report(y_test, y_pred_entropy))

print("\nConfusion Matrix with Gini:")
print(confusion_matrix(y_test, y_pred_gini))

print("\nConfusion Matrix with Entropy:")
print(confusion_matrix(y_test, y_pred_entropy))

# Plot the decision trees
plt.figure(figsize=(20,10))
plt.title("Decision Tree with Gini Impurity")
tree.plot_tree(dt_gini, filled=True, feature_names=feature_names, class_names=class_names)
plt.show()

plt.figure(figsize=(20,10))
plt.title("Decision Tree with Entropy")
tree.plot_tree(dt_entropy, filled=True, feature_names=feature_names, class_names=class_names)
plt.show()

# Access and print impurity values
n_nodes_gini = dt_gini.tree_.node_count
impurity_gini = dt_gini.tree_.impurity

n_nodes_entropy = dt_entropy.tree_.node_count
impurity_entropy = dt_entropy.tree_.impurity

print("\nImpurity values with Gini:")
for node in range(n_nodes_gini):
    print(f"Node {node}: Impurity = {impurity_gini[node]:.4f}")

print("\nImpurity values with Entropy:")
for node in range(n_nodes_entropy):
    print(f"Node {node}: Impurity = {impurity_entropy[node]:.4f}")

def calculate_entropy(probs):
    return -np.sum([p * np.log2(p) for p in probs if p > 0])

def calculate_gini(probs):
    return 1 - np.sum([p**2 for p in probs])

# Access tree structure
n_nodes = dt.tree_.node_count
children_left = dt.tree_.children_left
children_right = dt.tree_.children_right
feature = dt.tree_.feature
threshold = dt.tree_.threshold
value = dt.tree_.value

# Loop through each node and calculate entropy and Gini impurity
for node in range(n_nodes):
    if children_left[node] != children_right[node]:  # if not a leaf node
        # Calculate probabilities
        node_value = value[node][0]
        node_prob = node_value / node_value.sum()
        entropy = calculate_entropy(node_prob)
        gini = calculate_gini(node_prob)
        print(f"Node {node}: Entropy = {entropy:.4f}, Gini Impurity = {gini:.4f}")

"""**Random Forest**"""

from sklearn.ensemble import RandomForestClassifier




# Split data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X_train_res, y_train_res, test_size=0.2, random_state=42)

# Create a Random Forest model with 100 trees
rf = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the model on the training data
rf.fit(X_train, y_train)

# Make predictions on the validation set
y_pred = rf.predict(X_val)
y_pred_prob = rf.predict_proba(X_val)[:, 1]

# Evaluate the model
accuracy = accuracy_score(y_val, y_pred)
print("Accuracy:", accuracy)

# Print classification report
print("Classification Report:")
print(classification_report(y_val, y_pred))

# Print confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_val, y_pred))

# Calculate AUC
auc = roc_auc_score(y_val, y_pred_prob)

# ROC curve plot with AUC
plt.subplot(1, 3, 3)
fpr, tpr, _ = roc_curve(y_val, y_pred_prob)
plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % auc)
plt.plot([0, 1], [0, 1], color='red', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")

plt.tight_layout()
plt.show()